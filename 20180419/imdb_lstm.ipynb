{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:10:50.764222Z",
     "start_time": "2018-08-17T08:10:50.757849Z"
    }
   },
   "source": [
    "# IMDB - LSTM\n",
    "\n",
    "Trains an LSTM model on the IMDB sentiment classification task.\n",
    "\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- RNNs are tricky.\n",
    "\n",
    "    Choice of batch size is important, choice of loss and optimizer is critical, etc. Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different from what you see with CNNs/MLPs/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:12:30.164042Z",
     "start_time": "2018-08-17T08:12:26.742870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:12:35.753306Z",
     "start_time": "2018-08-17T08:12:35.745604Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:12:55.038182Z",
     "start_time": "2018-08-17T08:12:48.192420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:12:57.851933Z",
     "start_time": "2018-08-17T08:12:56.818488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T08:13:12.241849Z",
     "start_time": "2018-08-17T08:13:11.213579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T09:05:02.484029Z",
     "start_time": "2018-08-17T08:13:15.181916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 187s 7ms/step - loss: 0.4575 - acc: 0.7830 - val_loss: 0.3997 - val_acc: 0.8226\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 181s 7ms/step - loss: 0.2987 - acc: 0.8783 - val_loss: 0.3763 - val_acc: 0.8340\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.2178 - acc: 0.9164 - val_loss: 0.4402 - val_acc: 0.8260\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 177s 7ms/step - loss: 0.1557 - acc: 0.9405 - val_loss: 0.4620 - val_acc: 0.8317\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.1110 - acc: 0.9598 - val_loss: 0.6160 - val_acc: 0.8196\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 178s 7ms/step - loss: 0.0794 - acc: 0.9731 - val_loss: 0.6132 - val_acc: 0.8252\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.0572 - acc: 0.9810 - val_loss: 0.6900 - val_acc: 0.8242\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 185s 7ms/step - loss: 0.0414 - acc: 0.9864 - val_loss: 0.7209 - val_acc: 0.8124\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.0301 - acc: 0.9906 - val_loss: 0.9873 - val_acc: 0.8084\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 243s 10ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.9895 - val_acc: 0.8150\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 287s 11ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.9065 - val_acc: 0.8182\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 234s 9ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 1.0308 - val_acc: 0.8158\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 250s 10ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 1.0517 - val_acc: 0.8085\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 1.1163 - val_acc: 0.8109\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 169s 7ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 1.1646 - val_acc: 0.8096\n",
      "25000/25000 [==============================] - 24s 968us/step\n",
      "Test score: 1.1645919363\n",
      "Test accuracy: 0.80964\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
